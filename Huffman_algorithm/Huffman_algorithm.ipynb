{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorytmy Tekstowe lab4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Norbert Wolniak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_bytes(code):\n",
    "    zeros = 8 - (len(code) % 8)\n",
    "    info_byte = format(zeros, \"08b\")\n",
    "    b = bytearray()\n",
    "    b.append(int(info_byte,2))\n",
    "    for i in range(0, len(code), 8):\n",
    "        b.append(int(code[i:i+8], 2))\n",
    "    return bytes(b)\n",
    "\n",
    "def str_from_bytes(bytes):\n",
    "    zeros = bytes[0]\n",
    "    code = \"\"\n",
    "    for byte in bytes[1:-1]:\n",
    "        code += format(byte, \"08b\")\n",
    "    code += format(bytes[-1], \"08b\")[zeros:]\n",
    "    return code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Huffman algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, char, weight, left=None, right=None):\n",
    "        self.char = char\n",
    "        self.weight = weight\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        \n",
    "    def __lt__(self, other):\n",
    "        return self.weight < other.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "class StaticHuffmanTree:\n",
    "    def __init__(self, file_to_read, file_to_write):\n",
    "        text = None\n",
    "        with open(file_to_read, encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "            text = f.read()\n",
    "        self.file_to_write = file_to_write\n",
    "        self.root = self.create_tree(text)\n",
    "        self.huffman_code = {}\n",
    "        self._create_huffman_code(self.root)\n",
    "        self.encode(text)\n",
    "    \n",
    "    def create_tree(self, text):\n",
    "        pq = queue.PriorityQueue()\n",
    "        letter_counts = {}\n",
    "        for char in text:\n",
    "            if char in letter_counts:\n",
    "                letter_counts[char] += 1\n",
    "            else:\n",
    "                letter_counts[char] = 1\n",
    "                \n",
    "        for char,count in letter_counts.items():\n",
    "            pq.put(Node(char, count))\n",
    "        \n",
    "        while pq.qsize() > 1:\n",
    "            left = pq.get()\n",
    "            right = pq.get()\n",
    "            pq.put(Node(None, left.weight + right.weight, left, right))\n",
    "        \n",
    "        return pq.get()\n",
    "    \n",
    "    def _create_huffman_code(self, node=None, sequence=\"\"):\n",
    "        if node is not None and node.left is None and node.right is None:\n",
    "            self.huffman_code[node.char] = sequence\n",
    "            return\n",
    "        \n",
    "        self._create_huffman_code(node.left, sequence + \"0\")\n",
    "        self._create_huffman_code(node.right, sequence + \"1\")\n",
    "        \n",
    "    def encode(self, text):\n",
    "        encoded_text = \"\"\n",
    "        for letter in text:\n",
    "            encoded_text += self.huffman_code[letter]\n",
    "        with open(self.file_to_write, \"wb\") as f:\n",
    "            f.write(str_to_bytes(encoded_text))\n",
    "        \n",
    "    def decode(self):\n",
    "        with open(self.file_to_write, \"rb\") as f:\n",
    "            encoded_text = str_from_bytes(f.read())\n",
    "        decoded_text = \"\"\n",
    "        i = 0\n",
    "        text = \"\"\n",
    "        while i < len(encoded_text):\n",
    "            node = self.root\n",
    "            while node.left is not None and node.right is not None:\n",
    "                if encoded_text[i] == \"0\":\n",
    "                    node = node.left\n",
    "                else:\n",
    "                    node = node.right\n",
    "                i += 1\n",
    "            decoded_text += node.char\n",
    "            \n",
    "        return decoded_text  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Huffman algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeA:\n",
    "    def __init__(self, char, weight, order, parent=None, left=None, right=None):\n",
    "        self.char = char\n",
    "        self.weight = weight\n",
    "        self.order = order\n",
    "        self.parent = parent\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "    \n",
    "\n",
    "class AdaptiveHuffmanTree:\n",
    "    def __init__(self, file_to_read, file_to_write):\n",
    "        with open(file_to_read, encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "            text = f.read()\n",
    "        self.alphabet_size = len(set(text))\n",
    "        self.file_to_write = file_to_write\n",
    "        self.encode(text)\n",
    "        \n",
    "        \n",
    "    def encode(self, text):\n",
    "        self.root = NodeA(\"#\", 0, 2*self.alphabet_size + 1)\n",
    "        self.nodes = {self.root.char: self.root}\n",
    "        f = open(self.file_to_write, \"wb\")\n",
    "        encoded_text = \"\"\n",
    "        for char in text:\n",
    "            if char in self.nodes:\n",
    "                encoded_text += self._code(char, self.root)\n",
    "                self._increment(self.nodes[char])\n",
    "            else:\n",
    "                NYT = self.nodes[\"#\"]\n",
    "                encoded_text += self._code(NYT.char, self.root) + format(ord(char), \"08b\")\n",
    "                NYT.char = None\n",
    "\n",
    "                new_node = NodeA(char, 1, NYT.order - 1, parent=NYT)\n",
    "                new_NYT = NodeA(\"#\", 0, NYT.order - 2, parent=NYT)\n",
    "\n",
    "                self.nodes[char] = new_node\n",
    "\n",
    "                NYT.left = new_NYT\n",
    "                NYT.right = new_node\n",
    "\n",
    "                self.nodes[\"#\"] = new_NYT\n",
    "\n",
    "                self._increment(self.nodes[char].parent)\n",
    "        \n",
    "        with open(self.file_to_write, \"wb\") as f:\n",
    "            f.write(str_to_bytes(encoded_text))\n",
    "\n",
    "    \n",
    "    def decode(self):\n",
    "        self.root = NodeA(\"#\", 0, 2*self.alphabet_size + 1)\n",
    "        self.nodes = {self.root.char: self.root}\n",
    "        \n",
    "        with open(self.file_to_write, \"rb\") as f:\n",
    "            encoded_text = str_from_bytes(f.read())\n",
    "        decoded_text = \"\"\n",
    "        curr_node = self.root\n",
    "        i = 0\n",
    "        while i < len(encoded_text):\n",
    "            if curr_node.left is None and curr_node.right is None:\n",
    "                if curr_node.char == \"#\":\n",
    "                    char = chr(int(encoded_text[i:i+8],2))\n",
    "                    i += 8\n",
    "                    \n",
    "                else:\n",
    "                    char = curr_node.char\n",
    "                    \n",
    "                if char in self.nodes:\n",
    "                    self._increment(self.nodes[char])\n",
    "                else:\n",
    "                    NYT = self.nodes[\"#\"]\n",
    "                    NYT.char = None\n",
    "\n",
    "                    new_node = NodeA(char, 1, NYT.order - 1, parent=NYT)\n",
    "                    new_NYT = NodeA(\"#\", 0, NYT.order - 2, parent=NYT)\n",
    "\n",
    "                    self.nodes[char] = new_node\n",
    "\n",
    "                    NYT.left = new_NYT\n",
    "                    NYT.right = new_node\n",
    "\n",
    "                    self.nodes[\"#\"] = new_NYT\n",
    "\n",
    "                    self._increment(self.nodes[char].parent)\n",
    "                \n",
    "                decoded_text += char\n",
    "\n",
    "                curr_node = self.root\n",
    "            else:\n",
    "                if i < len(encoded_text):\n",
    "                    if encoded_text[i] == \"0\":\n",
    "                        curr_node = curr_node.left\n",
    "                    else:\n",
    "                        curr_node = curr_node.right\n",
    "                i += 1\n",
    "    \n",
    "        if curr_node.left is None and curr_node.right is None:\n",
    "            decoded_text += curr_node.char\n",
    "        \n",
    "        return decoded_text\n",
    "    \n",
    "    def _increment(self, node):\n",
    "        if node is None:\n",
    "            return\n",
    "        \n",
    "        if self._is_highest_order(node):\n",
    "            node.weight += 1\n",
    "            self._increment(node.parent)\n",
    "        else:\n",
    "            tmp = self._get_highest_order(node)\n",
    "            self._swap(node, self._get_highest_order(node))\n",
    "            node.weight += 1\n",
    "            self._increment(node.parent)\n",
    "            \n",
    "    def _is_highest_order(self, node):\n",
    "        for other in self.nodes.values():\n",
    "            if other.weight == node.weight and other.order > node.order:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def _get_highest_order(self, node):\n",
    "        weight = node.weight\n",
    "        order = node.order\n",
    "        highest_order_node = None\n",
    "        for other in self.nodes.values():\n",
    "            if other.weight == weight and other.order > order:\n",
    "                highest_order_node = other\n",
    "                order = highest_order_node.order\n",
    "        return highest_order_node\n",
    "        \n",
    "    def _swap(self, node, other):\n",
    "        other_parent = other.parent\n",
    "        node_parent = node.parent\n",
    "        node_order = node.order\n",
    "        \n",
    "        if other is other_parent.left:\n",
    "            other_parent.left = node\n",
    "        else:\n",
    "            other_parent.right = node\n",
    "        node.parent = other_parent\n",
    "        node.order = other.order\n",
    "        \n",
    "        if node is node_parent.left:\n",
    "            node_parent.left = other\n",
    "        else:\n",
    "            node_parent.right = other\n",
    "        other.parent = node_parent\n",
    "        other.order = node_order\n",
    "    \n",
    "    def _code(self, char, node, sequence=\"\"):\n",
    "        if node is not None and node.left is None and node.right is None:\n",
    "            if node.char == char:\n",
    "                return sequence\n",
    "            else:\n",
    "                return \"\"\n",
    "        else:\n",
    "            tmp = self._code(char, node.left, sequence + \"0\")\n",
    "            if not tmp:\n",
    "                tmp = self._code(char, node.right, sequence + \"1\")\n",
    "            return tmp\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress ratio function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_size(algorithm, file_to_read, file_to_write):\n",
    "    if algorithm.__name__ == \"StaticHuffmanTree\":\n",
    "        StaticHuffmanTree(file_to_read, file_to_write).decode()\n",
    "    elif algorithm.__name__ == \"AdaptiveHuffmanTree\":\n",
    "        AdaptiveHuffmanTree(file_to_read, file_to_write).decode()\n",
    "        \n",
    "    size_o = os.path.getsize(file_to_read)\n",
    "    size_c = os.path.getsize(file_to_write)\n",
    "    print(\"Algorithm : {}\".format(algorithm.__name__))\n",
    "    print(\"File name : {}\".format(file_to_read))\n",
    "    print(\"Uncompressed file size : {} bytes\".format(size_o))\n",
    "    print(\"Compressed file size : {} bytes\".format(size_c))\n",
    "    print('Compression ratio : {}\\n\\n'.format(round(1 - size_c / size_o, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_test(algorithm, file_to_read, file_to_write):\n",
    "    if algorithm.__name__ == \"StaticHuffmanTree\":\n",
    "        #Encode\n",
    "        encode_start = datetime.now()\n",
    "        tree = StaticHuffmanTree(file_to_read, file_to_write)\n",
    "        encode_time = (datetime.now() - encode_start).total_seconds()\n",
    "        #Decode\n",
    "        decode_start = datetime.now()\n",
    "        tree.decode()\n",
    "        decode_time = (datetime.now() - decode_start).total_seconds()\n",
    "    elif algorithm.__name__ == \"AdaptiveHuffmanTree\":\n",
    "        #Encode\n",
    "        encode_start = datetime.now()\n",
    "        tree = AdaptiveHuffmanTree(file_to_read, file_to_write)\n",
    "        encode_time = (datetime.now() - encode_start).total_seconds()\n",
    "        #Decode\n",
    "        decode_start = datetime.now()\n",
    "        tree.decode()\n",
    "        decode_time = (datetime.now() - decode_start).total_seconds()\n",
    "    \n",
    "    print(\"Algorithm : {}\".format(algorithm.__name__))\n",
    "    print(\"Encode time : {} [s]\".format(encode_time))\n",
    "    print(\"Decode time : {} [s]\\n\".format(decode_time))\n",
    "    \n",
    "    return encode_time, decode_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_encode_times = []\n",
    "adaptive_encode_times = []\n",
    "static_decode_times = []\n",
    "adaptive_decode_times = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test poprawności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abracadabra\n"
     ]
    }
   ],
   "source": [
    "print(StaticHuffmanTree(\"test.txt\", \"test_static.txt\").decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abracadabra\n"
     ]
    }
   ],
   "source": [
    "print(AdaptiveHuffmanTree(\"test.txt\", \"test_static.txt\").decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random text files :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 kB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm : StaticHuffmanTree\n",
      "File name : 1KB.txt\n",
      "Uncompressed file size : 1024 bytes\n",
      "Compressed file size : 607 bytes\n",
      "Compression ratio : 0.41\n",
      "\n",
      "\n",
      "Algorithm : AdaptiveHuffmanTree\n",
      "File name : 1KB.txt\n",
      "Uncompressed file size : 1024 bytes\n",
      "Compressed file size : 647 bytes\n",
      "Compression ratio : 0.37\n",
      "\n",
      "\n",
      "Algorithm : StaticHuffmanTree\n",
      "Encode time : 0.001 [s]\n",
      "Decode time : 0.00503 [s]\n",
      "\n",
      "Algorithm : AdaptiveHuffmanTree\n",
      "Encode time : 0.03997 [s]\n",
      "Decode time : 0.030031 [s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size(StaticHuffmanTree, \"1KB.txt\", \"1KB_static_compressed.bin\")\n",
    "test_size(AdaptiveHuffmanTree, \"1KB.txt\", \"1KB_adaptive_compressed.bin\")\n",
    "\n",
    "time = time_test(StaticHuffmanTree, \"1KB.txt\", \"1KB_static_compressed.bin\")\n",
    "static_encode_times.append(time[0])\n",
    "adaptive_encode_times.append(time[1])\n",
    "\n",
    "time = time_test(AdaptiveHuffmanTree, \"1KB.txt\", \"1KB_adaptive_compressed.bin\")\n",
    "adaptive_encode_times.append(time[0])\n",
    "adaptive_decode_times.append(time[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 kB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm : StaticHuffmanTree\n",
      "File name : 10KB.txt\n",
      "Uncompressed file size : 10240 bytes\n",
      "Compressed file size : 6088 bytes\n",
      "Compression ratio : 0.41\n",
      "\n",
      "\n",
      "Algorithm : AdaptiveHuffmanTree\n",
      "File name : 10KB.txt\n",
      "Uncompressed file size : 10240 bytes\n",
      "Compressed file size : 6184 bytes\n",
      "Compression ratio : 0.4\n",
      "\n",
      "\n",
      "Algorithm : StaticHuffmanTree\n",
      "Encode time : 0.008003 [s]\n",
      "Decode time : 0.020996 [s]\n",
      "\n",
      "Algorithm : AdaptiveHuffmanTree\n",
      "Encode time : 0.348965 [s]\n",
      "Decode time : 0.292033 [s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size(StaticHuffmanTree, \"10KB.txt\", \"10KB_static_compressed.bin\")\n",
    "test_size(AdaptiveHuffmanTree, \"10KB.txt\", \"10KB_adaptive_compressed.bin\")\n",
    "\n",
    "time = time_test(StaticHuffmanTree, \"10KB.txt\", \"10KB_static_compressed.bin\")\n",
    "static_encode_times.append(time[0])\n",
    "adaptive_encode_times.append(time[1])\n",
    "\n",
    "time = time_test(AdaptiveHuffmanTree, \"10KB.txt\", \"10KB_adaptive_compressed.bin\")\n",
    "adaptive_encode_times.append(time[0])\n",
    "adaptive_decode_times.append(time[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100 kB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm : StaticHuffmanTree\n",
      "File name : 100KB.txt\n",
      "Uncompressed file size : 102400 bytes\n",
      "Compressed file size : 60967 bytes\n",
      "Compression ratio : 0.4\n",
      "\n",
      "\n",
      "Algorithm : AdaptiveHuffmanTree\n",
      "File name : 100KB.txt\n",
      "Uncompressed file size : 102400 bytes\n",
      "Compressed file size : 61530 bytes\n",
      "Compression ratio : 0.4\n",
      "\n",
      "\n",
      "Algorithm : StaticHuffmanTree\n",
      "Encode time : 0.062002 [s]\n",
      "Decode time : 0.190144 [s]\n",
      "\n",
      "Algorithm : AdaptiveHuffmanTree\n",
      "Encode time : 3.384165 [s]\n",
      "Decode time : 2.450985 [s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size(StaticHuffmanTree, \"100KB.txt\", \"100KB_static_compressed.bin\")\n",
    "test_size(AdaptiveHuffmanTree, \"100KB.txt\", \"100KB_adaptive_compressed.bin\")\n",
    "\n",
    "time = time_test(StaticHuffmanTree, \"100KB.txt\", \"100KB_static_compressed.bin\")\n",
    "static_encode_times.append(time[0])\n",
    "adaptive_encode_times.append(time[1])\n",
    "\n",
    "time = time_test(AdaptiveHuffmanTree, \"100KB.txt\", \"100KB_adaptive_compressed.bin\")\n",
    "adaptive_encode_times.append(time[0])\n",
    "adaptive_decode_times.append(time[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniform distribution ~ 147KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "s = np.random.uniform(0,255,100000)\n",
    "s = \"\".join([chr(int(r)) for r in s])\n",
    "with open(\"uniform.txt\", \"w\", encoding=\"utf-8\", errors=\"surrogateescape\") as f:\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm : StaticHuffmanTree\n",
      "File name : uniform.txt\n",
      "Uncompressed file size : 150366 bytes\n",
      "Compressed file size : 99854 bytes\n",
      "Compression ratio : 0.34\n",
      "\n",
      "\n",
      "Algorithm : AdaptiveHuffmanTree\n",
      "File name : uniform.txt\n",
      "Uncompressed file size : 150366 bytes\n",
      "Compressed file size : 100215 bytes\n",
      "Compression ratio : 0.33\n",
      "\n",
      "\n",
      "Algorithm : StaticHuffmanTree\n",
      "Encode time : 0.099992 [s]\n",
      "Decode time : 0.307996 [s]\n",
      "\n",
      "Algorithm : AdaptiveHuffmanTree\n",
      "Encode time : 36.838307 [s]\n",
      "Decode time : 24.795063 [s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size(StaticHuffmanTree, \"uniform.txt\", \"uniform_static_compressed.bin\")\n",
    "test_size(AdaptiveHuffmanTree, \"uniform.txt\", \"uniform_adaptive_compressed.bin\")\n",
    "\n",
    "time = time_test(StaticHuffmanTree,  \"uniform.txt\", \"uniform_static_compressed.bin\")\n",
    "static_encode_times.append(time[0])\n",
    "adaptive_encode_times.append(time[1])\n",
    "\n",
    "time = time_test(AdaptiveHuffmanTree, \"uniform.txt\", \"uniform_adaptive_compressed.bin\")\n",
    "adaptive_encode_times.append(time[0])\n",
    "adaptive_decode_times.append(time[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linux 506KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm : StaticHuffmanTree\n",
      "File name : linux2.txt\n",
      "Uncompressed file size : 517486 bytes\n",
      "Compressed file size : 352192 bytes\n",
      "Compression ratio : 0.32\n",
      "\n",
      "\n",
      "Algorithm : AdaptiveHuffmanTree\n",
      "File name : linux2.txt\n",
      "Uncompressed file size : 517486 bytes\n",
      "Compressed file size : 354418 bytes\n",
      "Compression ratio : 0.32\n",
      "\n",
      "\n",
      "Algorithm : StaticHuffmanTree\n",
      "Encode time : 0.657031 [s]\n",
      "Decode time : 1.386391 [s]\n",
      "\n",
      "Algorithm : AdaptiveHuffmanTree\n",
      "Encode time : 55.123501 [s]\n",
      "Decode time : 28.580729 [s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size(StaticHuffmanTree, \"linux2.txt\", \"linux2_static_compressed.bin\")\n",
    "test_size(AdaptiveHuffmanTree, \"linux2.txt\", \"linux2_adaptive_compressed.bin\")\n",
    "\n",
    "time = time_test(StaticHuffmanTree,  \"linux2.txt\", \"linux2_static_compressed.bin\")\n",
    "static_encode_times.append(time[0])\n",
    "adaptive_encode_times.append(time[1])\n",
    "\n",
    "time = time_test(AdaptiveHuffmanTree, \"linux2.txt\", \"linux2_adaptive_compressed.bin\")\n",
    "adaptive_encode_times.append(time[0])\n",
    "adaptive_decode_times.append(time[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linux 672KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm : StaticHuffmanTree\n",
      "File name : linux1.txt\n",
      "Uncompressed file size : 688096 bytes\n",
      "Compressed file size : 450918 bytes\n",
      "Compression ratio : 0.34\n",
      "\n",
      "\n",
      "Algorithm : AdaptiveHuffmanTree\n",
      "File name : linux1.txt\n",
      "Uncompressed file size : 688096 bytes\n",
      "Compressed file size : 463847 bytes\n",
      "Compression ratio : 0.33\n",
      "\n",
      "\n",
      "Algorithm : StaticHuffmanTree\n",
      "Encode time : 0.912028 [s]\n",
      "Decode time : 1.876092 [s]\n",
      "\n",
      "Algorithm : AdaptiveHuffmanTree\n",
      "Encode time : 75.53816 [s]\n",
      "Decode time : 31.5014 [s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size(StaticHuffmanTree, \"linux1.txt\", \"linux1_static_compressed.bin\")\n",
    "test_size(AdaptiveHuffmanTree, \"linux1.txt\", \"linux1_adaptive_compressed.bin\")\n",
    "\n",
    "time = time_test(StaticHuffmanTree,  \"linux1.txt\", \"linux1_static_compressed.bin\")\n",
    "static_encode_times.append(time[0])\n",
    "adaptive_encode_times.append(time[1])\n",
    "\n",
    "time = time_test(AdaptiveHuffmanTree, \"linux1.txt\", \"linux1_adaptive_compressed.bin\")\n",
    "adaptive_encode_times.append(time[0])\n",
    "adaptive_decode_times.append(time[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book 844kB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm : StaticHuffmanTree\n",
      "File name : book.txt\n",
      "Uncompressed file size : 260308 bytes\n",
      "Compressed file size : 140117 bytes\n",
      "Compression ratio : 0.46\n",
      "\n",
      "\n",
      "Algorithm : AdaptiveHuffmanTree\n",
      "File name : book.txt\n",
      "Uncompressed file size : 260308 bytes\n",
      "Compressed file size : 146828 bytes\n",
      "Compression ratio : 0.44\n",
      "\n",
      "\n",
      "Algorithm : StaticHuffmanTree\n",
      "Encode time : 0.193997 [s]\n",
      "Decode time : 0.493004 [s]\n",
      "\n",
      "Algorithm : AdaptiveHuffmanTree\n",
      "Encode time : 25.150145 [s]\n",
      "Decode time : 9.590814 [s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size(StaticHuffmanTree, \"book.txt\", \"book_static_compressed.bin\")\n",
    "test_size(AdaptiveHuffmanTree, \"book.txt\", \"book_adaptive_compressed.bin\")\n",
    "\n",
    "time = time_test(StaticHuffmanTree, \"book.txt\", \"book_static_compressed.bin\")\n",
    "static_encode_times.append(time[0])\n",
    "adaptive_encode_times.append(time[1])\n",
    "\n",
    "time = time_test(AdaptiveHuffmanTree, \"book.txt\", \"book_adaptive_compressed.bin\")\n",
    "adaptive_encode_times.append(time[0])\n",
    "adaptive_decode_times.append(time[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm : StaticHuffmanTree\n",
      "File name : 1MB.txt\n",
      "Uncompressed file size : 1048576 bytes\n",
      "Compressed file size : 624869 bytes\n",
      "Compression ratio : 0.4\n",
      "\n",
      "\n",
      "Algorithm : AdaptiveHuffmanTree\n",
      "File name : 1MB.txt\n",
      "Uncompressed file size : 1048576 bytes\n",
      "Compressed file size : 630119 bytes\n",
      "Compression ratio : 0.4\n",
      "\n",
      "\n",
      "Algorithm : StaticHuffmanTree\n",
      "Encode time : 1.357966 [s]\n",
      "Decode time : 2.590673 [s]\n",
      "\n",
      "Algorithm : AdaptiveHuffmanTree\n",
      "Encode time : 32.681079 [s]\n",
      "Decode time : 23.803335 [s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_size(StaticHuffmanTree, \"1MB.txt\", \"1MB_static_compressed.bin\")\n",
    "test_size(AdaptiveHuffmanTree, \"1MB.txt\", \"1MB_adaptive_compressed.bin\")\n",
    "\n",
    "time = time_test(StaticHuffmanTree, \"1MB.txt\", \"1MB_static_compressed.bin\")\n",
    "static_encode_times.append(time[0])\n",
    "adaptive_encode_times.append(time[1])\n",
    "\n",
    "time = time_test(AdaptiveHuffmanTree, \"1MB.txt\", \"1MB_adaptive_compressed.bin\")\n",
    "adaptive_encode_times.append(time[0])\n",
    "adaptive_decode_times.append(time[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
